{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "admission.pynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9QxomGmafp49KlGCPOqLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parikshithrao/ML/blob/master/admission_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NZwGYrkWbp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWNFCXCb6Pkk",
        "colab_type": "code",
        "outputId": "e5889aab-cc21-407c-bb6a-b19ae9468f48",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7fb5136b-ae61-4156-bd4b-6be45edce305\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7fb5136b-ae61-4156-bd4b-6be45edce305\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"parikshithh\",\"key\":\"92797f1131200a15ac8cdb4aa9898829\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jYeJbd-6UMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRcVa8ld7b96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66_O0Y9m78Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgZgCQy8GPM",
        "colab_type": "code",
        "outputId": "9aaf8f4a-d97d-4583-8fc8-17078407b3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                             title                                                size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "allen-institute-for-ai/CORD-19-research-challenge               COVID-19 Open Research Dataset Challenge (CORD-19)    3GB  2020-06-10 00:09:23          71785  \n",
            "roche-data-science-coalition/uncover                            UNCOVER COVID-19 Challenge                          179MB  2020-05-21 18:57:53          10483  \n",
            "kwullum/fatal-police-shootings-in-the-us                        Fatal Police Shootings in the US                      1MB  2017-09-22 19:18:21          12617  \n",
            "Cornell-University/arxiv                                        ArXiv Metadata                                        2GB  2020-05-06 23:18:35              2  \n",
            "yash612/stockmarket-sentiment-dataset                           Stock-Market Sentiment Dataset                      201KB  2020-06-05 19:16:19              0  \n",
            "cprete/covid19-open-datasets-for-brazil                         COVID-19 Open Datasets for Brazil                   139MB  2020-06-07 15:36:31              0  \n",
            "mohitkr05/global-significant-earthquake-database-from-2150bc    Global Significant Earthquake Database from 2150BC  216KB  2020-06-08 09:41:18              0  \n",
            "andrewmvd/global-education-statistics                           Global Education Statistics                          38MB  2020-06-06 04:35:48              0  \n",
            "sudalairajkumar/daily-temperature-of-major-cities               Daily Temperature of Major Cities                    13MB  2020-06-05 07:34:48              0  \n",
            "thoolihan/los-angeles-1992-riot-deaths-from-la-times            Los Angeles 1992 Riot Deaths from LA Times           16KB  2020-06-03 21:09:07              0  \n",
            "batjoker/zomato-restaurants-hyderabad                           Zomato Restaurants Hyderabad                          1MB  2020-06-08 15:11:39              0  \n",
            "paultimothymooney/minneapolis-police-stops-and-police-violence  Minneapolis Police Stops and Police Violence          8MB  2020-06-11 20:47:15              0  \n",
            "imdevskp/hiv-aids-dataset                                       HIV AIDS Dataset                                     37KB  2020-06-11 12:59:45              0  \n",
            "longnguyen2306/bacteria-detection-with-darkfield-microscopy     Bacteria detection with darkfield microscopy        162MB  2020-06-08 10:31:54              0  \n",
            "jpmiller/police-violence-in-the-us                              US Police Violence & Fatalities                      13MB  2020-06-11 04:31:21              0  \n",
            "benroshan/factors-affecting-campus-placement                    Campus Recruitment                                    5KB  2020-04-11 11:09:02           5523  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min      League of Legends Diamond Ranked Games (10 min)     539KB  2020-04-13 13:53:02           2542  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset               US counties COVID 19 dataset                          2MB  2020-06-11 12:18:09           7247  \n",
            "divyansh22/flight-delay-prediction                              January Flight Delay Prediction                      23MB  2020-04-14 13:15:41           1850  \n",
            "clmentbisaillon/fake-and-real-news-dataset                      Fake and real news dataset                           41MB  2020-03-26 18:51:15           4998  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T45kx6_c8NU8",
        "colab_type": "code",
        "outputId": "69b796e6-0e50-4432-e0f8-d9c4c668840e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! kaggle datasets download -d mohansacharya/graduate-admissions"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graduate-admissions.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spw6lb6y8Y0h",
        "colab_type": "code",
        "outputId": "1de32178-5a93-4291-c139-a3f5503ce67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! unzip /content/graduate-admissions.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/graduate-admissions.zip\n",
            "replace Admission_Predict.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Admission_Predict.csv   \n",
            "replace Admission_Predict_Ver1.1.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Admission_Predict_Ver1.1.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUCiH9z48hXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8rFyAIs8nYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFIEo9yj_yQd",
        "colab_type": "text"
      },
      "source": [
        "**Context**\n",
        "This dataset is created for prediction of Graduate Admissions from an Indian perspective.\n",
        "\n",
        "**Content**\n",
        "The dataset contains several parameters which are considered important during the application for Masters Programs.\n",
        "The parameters included are :\n",
        "\n",
        "GRE Scores ( out of 340 )\n",
        "TOEFL Scores ( out of 120 )\n",
        "University Rating ( out of 5 )\n",
        "Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
        "Undergraduate GPA ( out of 10 )\n",
        "Research Experience ( either 0 or 1 )\n",
        "Chance of Admit ( ranging from 0 to 1 )\n",
        "\n",
        "**Acknowledgements**\n",
        "\n",
        "This dataset is inspired by the UCLA Graduate Dataset. The test scores and GPA are in the older format.\n",
        "The dataset is owned by Mohan S Acharya.\n",
        "\n",
        "Inspiration\n",
        "This dataset was built with the purpose of helping students in shortlisting universities with their profiles. The predicted output gives them a fair idea about their chances for a particular university.\n",
        "\n",
        "Citation\n",
        "Please cite the following if you are interested in using the dataset :\n",
        "Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
        "\n",
        "I would like to thank all of you for contributing to this dataset through discussions and questions. I am in awe of the number of kernels built on this dataset. Some results and visualisations are fantastic and makes me a proud owner of the dataset. Keep em' coming! Thank You.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln3GwlgQ8qxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/Admission_Predict.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGJmeghr909n",
        "colab_type": "text"
      },
      "source": [
        "Read csv file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdsueGyE9UtS",
        "colab_type": "code",
        "outputId": "c60b29fb-b836-4e26-aded-1de68f31ee02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        }
      },
      "source": [
        "df.head(30)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>330</td>\n",
              "      <td>115</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.34</td>\n",
              "      <td>1</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>321</td>\n",
              "      <td>109</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>308</td>\n",
              "      <td>101</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>302</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>323</td>\n",
              "      <td>108</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>325</td>\n",
              "      <td>106</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.40</td>\n",
              "      <td>1</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>327</td>\n",
              "      <td>111</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>328</td>\n",
              "      <td>112</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>307</td>\n",
              "      <td>109</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>311</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.20</td>\n",
              "      <td>1</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>314</td>\n",
              "      <td>105</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>317</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.70</td>\n",
              "      <td>0</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>319</td>\n",
              "      <td>106</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>318</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>303</td>\n",
              "      <td>102</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>312</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>1</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>325</td>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>328</td>\n",
              "      <td>116</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>334</td>\n",
              "      <td>119</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>336</td>\n",
              "      <td>119</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>340</td>\n",
              "      <td>120</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>322</td>\n",
              "      <td>109</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>298</td>\n",
              "      <td>98</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>7.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>295</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>310</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n",
              "0            1        337          118  ...  9.65         1              0.92\n",
              "1            2        324          107  ...  8.87         1              0.76\n",
              "2            3        316          104  ...  8.00         1              0.72\n",
              "3            4        322          110  ...  8.67         1              0.80\n",
              "4            5        314          103  ...  8.21         0              0.65\n",
              "5            6        330          115  ...  9.34         1              0.90\n",
              "6            7        321          109  ...  8.20         1              0.75\n",
              "7            8        308          101  ...  7.90         0              0.68\n",
              "8            9        302          102  ...  8.00         0              0.50\n",
              "9           10        323          108  ...  8.60         0              0.45\n",
              "10          11        325          106  ...  8.40         1              0.52\n",
              "11          12        327          111  ...  9.00         1              0.84\n",
              "12          13        328          112  ...  9.10         1              0.78\n",
              "13          14        307          109  ...  8.00         1              0.62\n",
              "14          15        311          104  ...  8.20         1              0.61\n",
              "15          16        314          105  ...  8.30         0              0.54\n",
              "16          17        317          107  ...  8.70         0              0.66\n",
              "17          18        319          106  ...  8.00         1              0.65\n",
              "18          19        318          110  ...  8.80         0              0.63\n",
              "19          20        303          102  ...  8.50         0              0.62\n",
              "20          21        312          107  ...  7.90         1              0.64\n",
              "21          22        325          114  ...  8.40         0              0.70\n",
              "22          23        328          116  ...  9.50         1              0.94\n",
              "23          24        334          119  ...  9.70         1              0.95\n",
              "24          25        336          119  ...  9.80         1              0.97\n",
              "25          26        340          120  ...  9.60         1              0.94\n",
              "26          27        322          109  ...  8.80         0              0.76\n",
              "27          28        298           98  ...  7.50         1              0.44\n",
              "28          29        295           93  ...  7.20         0              0.46\n",
              "29          30        310           99  ...  7.30         0              0.54\n",
              "\n",
              "[30 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NLoPAct-F25",
        "colab_type": "code",
        "outputId": "5f4c21bc-675f-4fa9-abc4-044f87bc886c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         400 non-null    int64  \n",
            " 1   GRE Score          400 non-null    int64  \n",
            " 2   TOEFL Score        400 non-null    int64  \n",
            " 3   University Rating  400 non-null    int64  \n",
            " 4   SOP                400 non-null    float64\n",
            " 5   LOR                400 non-null    float64\n",
            " 6   CGPA               400 non-null    float64\n",
            " 7   Research           400 non-null    int64  \n",
            " 8   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 28.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHbtK2VN-bxF",
        "colab_type": "code",
        "outputId": "b73738d1-a74d-445c-bd13-6a8e4fb35d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>200.500000</td>\n",
              "      <td>316.807500</td>\n",
              "      <td>107.410000</td>\n",
              "      <td>3.087500</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>3.452500</td>\n",
              "      <td>8.598925</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.724350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>115.614301</td>\n",
              "      <td>11.473646</td>\n",
              "      <td>6.069514</td>\n",
              "      <td>1.143728</td>\n",
              "      <td>1.006869</td>\n",
              "      <td>0.898478</td>\n",
              "      <td>0.596317</td>\n",
              "      <td>0.498362</td>\n",
              "      <td>0.142609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>100.750000</td>\n",
              "      <td>308.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>200.500000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>8.610000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>300.250000</td>\n",
              "      <td>325.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.062500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.920000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Serial No.   GRE Score  ...    Research  Chance of Admit \n",
              "count  400.000000  400.000000  ...  400.000000        400.000000\n",
              "mean   200.500000  316.807500  ...    0.547500          0.724350\n",
              "std    115.614301   11.473646  ...    0.498362          0.142609\n",
              "min      1.000000  290.000000  ...    0.000000          0.340000\n",
              "25%    100.750000  308.000000  ...    0.000000          0.640000\n",
              "50%    200.500000  317.000000  ...    1.000000          0.730000\n",
              "75%    300.250000  325.000000  ...    1.000000          0.830000\n",
              "max    400.000000  340.000000  ...    1.000000          0.970000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NVskYMP-kf7",
        "colab_type": "code",
        "outputId": "990ededf-aaf5-43af-db62-81dc9fae66bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "df.corr()\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Serial No.</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.097526</td>\n",
              "      <td>-0.147932</td>\n",
              "      <td>-0.169948</td>\n",
              "      <td>-0.166932</td>\n",
              "      <td>-0.088221</td>\n",
              "      <td>-0.045608</td>\n",
              "      <td>-0.063138</td>\n",
              "      <td>0.042336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRE Score</th>\n",
              "      <td>-0.097526</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.835977</td>\n",
              "      <td>0.668976</td>\n",
              "      <td>0.612831</td>\n",
              "      <td>0.557555</td>\n",
              "      <td>0.833060</td>\n",
              "      <td>0.580391</td>\n",
              "      <td>0.802610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOEFL Score</th>\n",
              "      <td>-0.147932</td>\n",
              "      <td>0.835977</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.695590</td>\n",
              "      <td>0.657981</td>\n",
              "      <td>0.567721</td>\n",
              "      <td>0.828417</td>\n",
              "      <td>0.489858</td>\n",
              "      <td>0.791594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>University Rating</th>\n",
              "      <td>-0.169948</td>\n",
              "      <td>0.668976</td>\n",
              "      <td>0.695590</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.734523</td>\n",
              "      <td>0.660123</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.447783</td>\n",
              "      <td>0.711250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SOP</th>\n",
              "      <td>-0.166932</td>\n",
              "      <td>0.612831</td>\n",
              "      <td>0.657981</td>\n",
              "      <td>0.734523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.729593</td>\n",
              "      <td>0.718144</td>\n",
              "      <td>0.444029</td>\n",
              "      <td>0.675732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOR</th>\n",
              "      <td>-0.088221</td>\n",
              "      <td>0.557555</td>\n",
              "      <td>0.567721</td>\n",
              "      <td>0.660123</td>\n",
              "      <td>0.729593</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.670211</td>\n",
              "      <td>0.396859</td>\n",
              "      <td>0.669889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CGPA</th>\n",
              "      <td>-0.045608</td>\n",
              "      <td>0.833060</td>\n",
              "      <td>0.828417</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.718144</td>\n",
              "      <td>0.670211</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.521654</td>\n",
              "      <td>0.873289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Research</th>\n",
              "      <td>-0.063138</td>\n",
              "      <td>0.580391</td>\n",
              "      <td>0.489858</td>\n",
              "      <td>0.447783</td>\n",
              "      <td>0.444029</td>\n",
              "      <td>0.396859</td>\n",
              "      <td>0.521654</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.553202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chance of Admit</th>\n",
              "      <td>0.042336</td>\n",
              "      <td>0.802610</td>\n",
              "      <td>0.791594</td>\n",
              "      <td>0.711250</td>\n",
              "      <td>0.675732</td>\n",
              "      <td>0.669889</td>\n",
              "      <td>0.873289</td>\n",
              "      <td>0.553202</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Serial No.  GRE Score  ...  Research  Chance of Admit \n",
              "Serial No.           1.000000  -0.097526  ... -0.063138          0.042336\n",
              "GRE Score           -0.097526   1.000000  ...  0.580391          0.802610\n",
              "TOEFL Score         -0.147932   0.835977  ...  0.489858          0.791594\n",
              "University Rating   -0.169948   0.668976  ...  0.447783          0.711250\n",
              "SOP                 -0.166932   0.612831  ...  0.444029          0.675732\n",
              "LOR                 -0.088221   0.557555  ...  0.396859          0.669889\n",
              "CGPA                -0.045608   0.833060  ...  0.521654          0.873289\n",
              "Research            -0.063138   0.580391  ...  1.000000          0.553202\n",
              "Chance of Admit      0.042336   0.802610  ...  0.553202          1.000000\n",
              "\n",
              "[9 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb4s6MqM-uT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVgipEN0-_v2",
        "colab_type": "code",
        "outputId": "f9420c87-b28f-4b59-f2ac-e25bb810d3ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "for column in columns:\n",
        "    if df[column].dtype == 'int':\n",
        "        print(column,\"total unique values are :\",df[column].unique(),'\\n')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial No. total unique values are : [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
            " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
            " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
            " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
            " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
            " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
            " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
            " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
            " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
            " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
            " 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
            " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
            " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
            " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
            " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
            " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
            " 397 398 399 400] \n",
            "\n",
            "GRE Score total unique values are : [337 324 316 322 314 330 321 308 302 323 325 327 328 307 311 317 319 318\n",
            " 303 312 334 336 340 298 295 310 300 338 331 320 299 304 313 332 326 329\n",
            " 339 309 315 301 296 294 306 305 290 335 333 297 293] \n",
            "\n",
            "TOEFL Score total unique values are : [118 107 104 110 103 115 109 101 102 108 106 111 112 105 114 116 119 120\n",
            "  98  93  99  97 117 113 100  95  96  94  92] \n",
            "\n",
            "University Rating total unique values are : [4 3 2 5 1] \n",
            "\n",
            "Research total unique values are : [1 0] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFdpR5Nb_Lm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['Chance of Admit ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssFh47uMB5g_",
        "colab_type": "code",
        "outputId": "b941cc45-4f54-48dd-b564-3fb992c5d134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>396</td>\n",
              "      <td>324</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.04</td>\n",
              "      <td>1</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>397</td>\n",
              "      <td>325</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>398</td>\n",
              "      <td>330</td>\n",
              "      <td>116</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>399</td>\n",
              "      <td>312</td>\n",
              "      <td>103</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>400</td>\n",
              "      <td>333</td>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.66</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n",
              "0             1        337          118  ...  9.65         1              0.92\n",
              "1             2        324          107  ...  8.87         1              0.76\n",
              "2             3        316          104  ...  8.00         1              0.72\n",
              "3             4        322          110  ...  8.67         1              0.80\n",
              "4             5        314          103  ...  8.21         0              0.65\n",
              "..          ...        ...          ...  ...   ...       ...               ...\n",
              "395         396        324          110  ...  9.04         1              0.82\n",
              "396         397        325          107  ...  9.11         1              0.84\n",
              "397         398        330          116  ...  9.45         1              0.91\n",
              "398         399        312          103  ...  8.78         0              0.67\n",
              "399         400        333          117  ...  9.66         1              0.95\n",
              "\n",
              "[400 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foy4Us_3B9yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(columns = ['Chance of Admit ', 'Serial No.'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6qNCFwFSTqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6a14f773-52f1-4dfe-856d-339c34616d26"
      },
      "source": [
        "X"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>324</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>325</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>330</td>\n",
              "      <td>116</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>312</td>\n",
              "      <td>103</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>333</td>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
              "0          337          118                  4  4.5   4.5  9.65         1\n",
              "1          324          107                  4  4.0   4.5  8.87         1\n",
              "2          316          104                  3  3.0   3.5  8.00         1\n",
              "3          322          110                  3  3.5   2.5  8.67         1\n",
              "4          314          103                  2  2.0   3.0  8.21         0\n",
              "..         ...          ...                ...  ...   ...   ...       ...\n",
              "395        324          110                  3  3.5   3.5  9.04         1\n",
              "396        325          107                  3  3.0   3.5  9.11         1\n",
              "397        330          116                  4  5.0   4.5  9.45         1\n",
              "398        312          103                  3  3.5   4.0  8.78         0\n",
              "399        333          117                  4  5.0   4.0  9.66         1\n",
              "\n",
              "[400 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQDCqm8dc8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1dff504a-589a-44a6-c782-4c01afe91d02"
      },
      "source": [
        "y"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.92\n",
              "1      0.76\n",
              "2      0.72\n",
              "3      0.80\n",
              "4      0.65\n",
              "       ... \n",
              "395    0.82\n",
              "396    0.84\n",
              "397    0.91\n",
              "398    0.67\n",
              "399    0.95\n",
              "Name: Chance of Admit , Length: 400, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pizgTP2JTmH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxQ-OGjdTrE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.2,random_state = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH4IY2hqXowu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49fc6d99-dd5c-44ef-c959-d53547d75c68"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPsmbUnXr_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27c2c89b-3e95-48d4-b471-55323c4b2a1c"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzleGh29X18P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arQXRzhZX-sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22300a66-0142-423e-f14a-dad3d4ce6d55"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FvRcfLHdolQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "259e029b-27c3-4f32-96bb-5c6143dd9ec5"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145    0.81\n",
              "387    0.53\n",
              "44     0.91\n",
              "138    0.80\n",
              "43     0.87\n",
              "       ... \n",
              "132    0.71\n",
              "289    0.79\n",
              "109    0.68\n",
              "395    0.82\n",
              "176    0.90\n",
              "Name: Chance of Admit , Length: 320, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zORnZ19gYEJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY94OhQQdsvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "2ca78008-31e9-44fc-aee2-9ccc0d3ed542"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.81, 0.53, 0.91, 0.8 , 0.87, 0.51, 0.96, 0.5 , 0.47, 0.85, 0.94,\n",
              "       0.84, 0.65, 0.87, 0.72, 0.77, 0.76, 0.97, 0.76, 0.79, 0.97, 0.75,\n",
              "       0.81, 0.71, 0.91, 0.86, 0.81, 0.77, 0.64, 0.88, 0.68, 0.77, 0.66,\n",
              "       0.68, 0.7 , 0.73, 0.63, 0.85, 0.64, 0.74, 0.59, 0.94, 0.79, 0.64,\n",
              "       0.54, 0.73, 0.72, 0.84, 0.78, 0.74, 0.82, 0.72, 0.76, 0.77, 0.54,\n",
              "       0.93, 0.72, 0.64, 0.66, 0.62, 0.56, 0.71, 0.7 , 0.61, 0.38, 0.82,\n",
              "       0.48, 0.65, 0.57, 0.62, 0.7 , 0.94, 0.96, 0.64, 0.49, 0.96, 0.93,\n",
              "       0.93, 0.92, 0.52, 0.8 , 0.94, 0.67, 0.52, 0.63, 0.76, 0.73, 0.91,\n",
              "       0.76, 0.92, 0.9 , 0.89, 0.94, 0.58, 0.67, 0.71, 0.72, 0.39, 0.95,\n",
              "       0.74, 0.73, 0.78, 0.94, 0.58, 0.84, 0.7 , 0.71, 0.65, 0.8 , 0.92,\n",
              "       0.72, 0.78, 0.8 , 0.61, 0.68, 0.97, 0.52, 0.85, 0.95, 0.77, 0.93,\n",
              "       0.71, 0.69, 0.58, 0.75, 0.64, 0.34, 0.71, 0.69, 0.71, 0.86, 0.64,\n",
              "       0.48, 0.64, 0.79, 0.46, 0.79, 0.86, 0.91, 0.53, 0.91, 0.73, 0.7 ,\n",
              "       0.87, 0.58, 0.85, 0.57, 0.68, 0.84, 0.9 , 0.42, 0.89, 0.88, 0.54,\n",
              "       0.78, 0.71, 0.79, 0.73, 0.63, 0.7 , 0.57, 0.72, 0.49, 0.7 , 0.59,\n",
              "       0.94, 0.76, 0.65, 0.52, 0.93, 0.46, 0.61, 0.59, 0.63, 0.65, 0.95,\n",
              "       0.72, 0.8 , 0.83, 0.62, 0.89, 0.74, 0.78, 0.81, 0.74, 0.49, 0.92,\n",
              "       0.68, 0.47, 0.62, 0.78, 0.94, 0.78, 0.67, 0.63, 0.6 , 0.5 , 0.36,\n",
              "       0.52, 0.85, 0.46, 0.64, 0.65, 0.47, 0.81, 0.45, 0.61, 0.72, 0.95,\n",
              "       0.64, 0.76, 0.71, 0.84, 0.7 , 0.77, 0.62, 0.68, 0.77, 0.73, 0.42,\n",
              "       0.71, 0.65, 0.9 , 0.69, 0.68, 0.73, 0.46, 0.9 , 0.97, 0.79, 0.44,\n",
              "       0.56, 0.89, 0.67, 0.92, 0.67, 0.43, 0.75, 0.65, 0.44, 0.7 , 0.62,\n",
              "       0.47, 0.81, 0.73, 0.7 , 0.34, 0.73, 0.89, 0.78, 0.82, 0.64, 0.69,\n",
              "       0.93, 0.71, 0.88, 0.82, 0.88, 0.66, 0.86, 0.47, 0.84, 0.84, 0.71,\n",
              "       0.64, 0.72, 0.54, 0.87, 0.73, 0.86, 0.7 , 0.56, 0.96, 0.78, 0.78,\n",
              "       0.81, 0.36, 0.75, 0.44, 0.92, 0.61, 0.72, 0.67, 0.62, 0.72, 0.48,\n",
              "       0.76, 0.69, 0.46, 0.96, 0.83, 0.75, 0.75, 0.87, 0.79, 0.78, 0.89,\n",
              "       0.71, 0.89, 0.84, 0.8 , 0.38, 0.57, 0.68, 0.57, 0.96, 0.74, 0.42,\n",
              "       0.77, 0.79, 0.86, 0.66, 0.89, 0.82, 0.94, 0.71, 0.79, 0.68, 0.82,\n",
              "       0.9 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLXXDOAYXqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leRcGsREdxO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aaa671bf-473f-47f4-9bea-c55407bd9cd8"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146    0.75\n",
              "332    0.75\n",
              "67     0.57\n",
              "362    0.91\n",
              "102    0.62\n",
              "       ... \n",
              "55     0.64\n",
              "65     0.55\n",
              "16     0.66\n",
              "153    0.79\n",
              "225    0.61\n",
              "Name: Chance of Admit , Length: 80, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XWNck4dYfop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nErJz1EwYn73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# no need to normalize data for regression values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_kSaF_Qa2Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9PTMc66bZDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor = LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWQwpf9bhP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ef1a9e3-0529-43f4-8b75-bfc6284870a1"
      },
      "source": [
        "\n",
        "regressor.fit(X_train,y_train)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsizGXUib_17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = regressor.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtNKO85_ccEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30a8d9e1-ddad-41cb-8808-e5e29652481f"
      },
      "source": [
        "y_pred[9]\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8004217371332953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBr9sVn_cd4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdc5a7be-5b73-4c25-c0e2-8ca1d028018e"
      },
      "source": [
        "\n",
        "y_test[9\n",
        "       ]"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbf8min-cxnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "00fe5e3b-b975-46a1-8ce2-6e0233ed0690"
      },
      "source": [
        ""
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.92\n",
              "1      0.76\n",
              "2      0.72\n",
              "3      0.80\n",
              "4      0.65\n",
              "       ... \n",
              "395    0.82\n",
              "396    0.84\n",
              "397    0.91\n",
              "398    0.67\n",
              "399    0.95\n",
              "Name: Chance of Admit , Length: 400, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfaDpaPDc1p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aliGeS_lgBtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model = 'my_model.sav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YZOUeD0e3eX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aeb19b98-3afa-42ad-d962-0ca7218ad1d7"
      },
      "source": [
        "joblib.dump( regressor, 'my_model')"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_model']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sST4I3PSfKDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = joblib.load('/content/my_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St2PLoPJfZ5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "73525ae3-7f0a-4ac6-b99a-4124a22fdd4e"
      },
      "source": [
        "model.predict(X_test)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66816926, 0.63624273, 0.73122214, 0.91807932, 0.65866257,\n",
              "       0.77019932, 0.67465277, 0.85075008, 0.8370863 , 0.80042174,\n",
              "       0.48056318, 0.66584472, 0.68620325, 0.61657599, 0.53355645,\n",
              "       0.57336479, 0.49646167, 0.82307466, 0.62536007, 0.69933237,\n",
              "       0.9672319 , 0.85839996, 0.86003093, 0.90411493, 0.62206212,\n",
              "       0.69831889, 0.64005358, 0.89966116, 0.80355934, 0.75630733,\n",
              "       0.90994904, 0.84070293, 0.59694903, 0.72751722, 0.71782846,\n",
              "       0.60565153, 0.59822195, 0.7088992 , 0.7832538 , 0.69810586,\n",
              "       0.93723918, 0.6595092 , 0.9532787 , 0.69738735, 0.68455438,\n",
              "       0.64827778, 0.65447539, 0.88099392, 0.95172157, 0.5197848 ,\n",
              "       0.46257415, 0.54745506, 0.79195137, 0.7259337 , 0.66500139,\n",
              "       0.65254347, 0.93792857, 0.74138918, 0.8814558 , 0.9516664 ,\n",
              "       0.67482617, 0.76304487, 0.80814566, 0.85859395, 0.52140877,\n",
              "       0.70155389, 0.90570557, 0.72509137, 0.71805487, 0.73638729,\n",
              "       0.76734751, 0.74163439, 0.73350435, 0.82704031, 0.66160972,\n",
              "       0.58799611, 0.78802902, 0.71434669, 0.75733023, 0.55231698])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtzbCAKlhGUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3aab4e45-aebe-4e09-8d73-65659d415e4e"
      },
      "source": [
        "model.predict(np.array([[340, 120, 4, 4.5, 4.5, 9, 0]]))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8737515])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ylRZ8wkho61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}